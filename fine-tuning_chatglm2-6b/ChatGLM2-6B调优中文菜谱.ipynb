{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7717416e",
   "metadata": {},
   "source": [
    "***本项目是用来演示使用中文菜谱数据调优ChatGLM2-6B***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b9f84f00-bb90-4c04-a178-aba73d09acab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/rainbowliao\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.abspath(os.curdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8346fb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: scipy in /root/miniconda3/lib/python3.8/site-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /root/miniconda3/lib/python3.8/site-packages (from scipy) (1.23.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: transformers in /root/miniconda3/lib/python3.8/site-packages (4.31.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/lib/python3.8/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (1.23.3)\n",
      "Requirement already satisfied: requests in /root/miniconda3/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: fsspec in /root/miniconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /root/miniconda3/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: sentencepiece in /root/miniconda3/lib/python3.8/site-packages (0.1.99)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: accelerate in /root/miniconda3/lib/python3.8/site-packages (0.21.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/lib/python3.8/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/lib/python3.8/site-packages (from accelerate) (5.9.2)\n",
      "Requirement already satisfied: pyyaml in /root/miniconda3/lib/python3.8/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /root/miniconda3/lib/python3.8/site-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/lib/python3.8/site-packages (from accelerate) (1.23.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /root/miniconda3/lib/python3.8/site-packages (from packaging>=20.0->accelerate) (3.0.9)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (11.7.91)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (8.5.0.96)\n",
      "Requirement already satisfied: sympy in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (11.7.101)\n",
      "Requirement already satisfied: typing-extensions in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (10.9.0.58)\n",
      "Requirement already satisfied: triton==2.0.0 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.12.2)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (10.2.10.91)\n",
      "Requirement already satisfied: setuptools in /root/miniconda3/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (52.0.0.post20210125)\n",
      "Requirement already satisfied: wheel in /root/miniconda3/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (0.36.2)\n",
      "Requirement already satisfied: lit in /root/miniconda3/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
      "Requirement already satisfied: cmake in /root/miniconda3/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.26.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/lib/python3.8/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /root/miniconda3/lib/python3.8/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: datasets in /root/miniconda3/lib/python3.8/site-packages (2.13.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /root/miniconda3/lib/python3.8/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: xxhash in /root/miniconda3/lib/python3.8/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /root/miniconda3/lib/python3.8/site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /root/miniconda3/lib/python3.8/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: pandas in /root/miniconda3/lib/python3.8/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: multiprocess in /root/miniconda3/lib/python3.8/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: packaging in /root/miniconda3/lib/python3.8/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/lib/python3.8/site-packages (from datasets) (1.23.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /root/miniconda3/lib/python3.8/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /root/miniconda3/lib/python3.8/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /root/miniconda3/lib/python3.8/site-packages (from datasets) (2.25.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /root/miniconda3/lib/python3.8/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/lib/python3.8/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/miniconda3/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /root/miniconda3/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /root/miniconda3/lib/python3.8/site-packages (from aiohttp->datasets) (3.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /root/miniconda3/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/miniconda3/lib/python3.8/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /root/miniconda3/lib/python3.8/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/miniconda3/lib/python3.8/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.7.1)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /root/miniconda3/lib/python3.8/site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /root/miniconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /root/miniconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /root/miniconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /root/miniconda3/lib/python3.8/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/lib/python3.8/site-packages (from pandas->datasets) (2022.4)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: peft in /root/miniconda3/lib/python3.8/site-packages (0.4.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /root/miniconda3/lib/python3.8/site-packages (from peft) (2.0.1)\n",
      "Requirement already satisfied: safetensors in /root/miniconda3/lib/python3.8/site-packages (from peft) (0.3.1)\n",
      "Requirement already satisfied: pyyaml in /root/miniconda3/lib/python3.8/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: transformers in /root/miniconda3/lib/python3.8/site-packages (from peft) (4.31.0)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/lib/python3.8/site-packages (from peft) (5.9.2)\n",
      "Requirement already satisfied: accelerate in /root/miniconda3/lib/python3.8/site-packages (from peft) (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/lib/python3.8/site-packages (from peft) (1.23.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/lib/python3.8/site-packages (from peft) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /root/miniconda3/lib/python3.8/site-packages (from packaging>=20.0->peft) (3.0.9)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.13.0->peft) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.13.0->peft) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.13.0->peft) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.13.0->peft) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.13.0->peft) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.13.0->peft) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.13.0->peft) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.13.0->peft) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.13.0->peft) (2.14.3)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.13.0->peft) (10.2.10.91)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.13.0->peft) (3.12.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.13.0->peft) (2.0.0)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.13.0->peft) (3.1)\n",
      "Requirement already satisfied: sympy in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: typing-extensions in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.13.0->peft) (4.7.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.13.0->peft) (11.7.4.91)\n",
      "Requirement already satisfied: setuptools in /root/miniconda3/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft) (52.0.0.post20210125)\n",
      "Requirement already satisfied: wheel in /root/miniconda3/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft) (0.36.2)\n",
      "Requirement already satisfied: cmake in /root/miniconda3/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.13.0->peft) (3.26.4)\n",
      "Requirement already satisfied: lit in /root/miniconda3/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.13.0->peft) (16.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/lib/python3.8/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /root/miniconda3/lib/python3.8/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /root/miniconda3/lib/python3.8/site-packages (from transformers->peft) (0.16.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /root/miniconda3/lib/python3.8/site-packages (from transformers->peft) (0.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/lib/python3.8/site-packages (from transformers->peft) (2023.6.3)\n",
      "Requirement already satisfied: requests in /root/miniconda3/lib/python3.8/site-packages (from transformers->peft) (2.25.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/miniconda3/lib/python3.8/site-packages (from transformers->peft) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /root/miniconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers->peft) (2023.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers->peft) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers->peft) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers->peft) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers->peft) (2.10)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: torchkeras in /root/miniconda3/lib/python3.8/site-packages (3.9.1)\n",
      "Requirement already satisfied: accelerate in /root/miniconda3/lib/python3.8/site-packages (from torchkeras) (0.21.0)\n",
      "Requirement already satisfied: tqdm in /root/miniconda3/lib/python3.8/site-packages (from torchkeras) (4.65.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/lib/python3.8/site-packages (from accelerate->torchkeras) (21.3)\n",
      "Requirement already satisfied: pyyaml in /root/miniconda3/lib/python3.8/site-packages (from accelerate->torchkeras) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /root/miniconda3/lib/python3.8/site-packages (from accelerate->torchkeras) (2.0.1)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/lib/python3.8/site-packages (from accelerate->torchkeras) (5.9.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/lib/python3.8/site-packages (from accelerate->torchkeras) (1.23.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /root/miniconda3/lib/python3.8/site-packages (from packaging>=20.0->accelerate->torchkeras) (3.0.9)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->torchkeras) (11.7.91)\n",
      "Requirement already satisfied: typing-extensions in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->torchkeras) (4.7.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->torchkeras) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->torchkeras) (11.7.101)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->torchkeras) (3.12.2)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->torchkeras) (8.5.0.96)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->torchkeras) (3.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->torchkeras) (2.14.3)\n",
      "Requirement already satisfied: sympy in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->torchkeras) (1.12)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->torchkeras) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->torchkeras) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->torchkeras) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->torchkeras) (11.7.99)\n",
      "Requirement already satisfied: triton==2.0.0 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->torchkeras) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->torchkeras) (11.7.99)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->torchkeras) (3.1.2)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->torchkeras) (10.2.10.91)\n",
      "Requirement already satisfied: wheel in /root/miniconda3/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate->torchkeras) (0.36.2)\n",
      "Requirement already satisfied: setuptools in /root/miniconda3/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate->torchkeras) (52.0.0.post20210125)\n",
      "Requirement already satisfied: cmake in /root/miniconda3/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate->torchkeras) (3.26.4)\n",
      "Requirement already satisfied: lit in /root/miniconda3/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate->torchkeras) (16.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/lib/python3.8/site-packages (from jinja2->torch>=1.10.0->accelerate->torchkeras) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /root/miniconda3/lib/python3.8/site-packages (from sympy->torch>=1.10.0->accelerate->torchkeras) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: bitsandbytes in /root/miniconda3/lib/python3.8/site-packages (0.40.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#安装必要的组件\n",
    "!pip install scipy\n",
    "#chatglm\n",
    "!pip install transformers\n",
    "!pip install sentencepiece\n",
    "\n",
    "#finetune\n",
    "!pip install -U accelerate\n",
    "!pip install datasets\n",
    "!pip install -U peft \n",
    "!pip install -U torchkeras \n",
    "!pip install bitsandbytes #==0.39.1  # 提供4bit量化支持，限制版本很重要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "285d63ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: bitsandbytes\n",
      "Version: 0.40.2\n",
      "Summary: k-bit optimizers and matrix multiplication routines.\n",
      "Home-page: https://github.com/TimDettmers/bitsandbytes\n",
      "Author: Tim Dettmers\n",
      "Author-email: dettmers@cs.washington.edu\n",
      "License: MIT\n",
      "Location: /root/miniconda3/lib/python3.8/site-packages\n",
      "Requires: \n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccf58b2",
   "metadata": {},
   "source": [
    "### 0. 测试ChatGLM原生的能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3d72b7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are loading your model in 8bit or 4bit but no linear modules were found in your model. Please double check your model architecture, or submit an issue on github if you think this is a bug.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd6b560226243fca4d8d4ab82177361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from transformers import  AutoModel,AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "model_name = \"THUDM/chatglm2-6b\" # \"../chatglm2-6b\" #或者远程 “THUDM/chatglm2-6b”\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True, #QLoRA 设计的 Double Quantization\n",
    "    bnb_4bit_quant_type='nf4', # QLoRA 设计的 Normal Float 4 量化数据类型\n",
    "    llm_int8_threshold=6.0,\n",
    "    llm_int8_has_fp16_weight=False,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(model_name,\n",
    "                                  quantization_config=bnb_config,\n",
    "                                  trust_remote_code=True) #.half().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3f3d97e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "宫保鸡丁是一道以鸡肉为主料的川菜。以下是一种宫保鸡丁的常见做法:\n",
      "\n",
      "所需材料:\n",
      "\n",
      "- 鸡脯肉 250 克\n",
      "- 干辣椒 3 根\n",
      "- 姜 1 片\n",
      "- 蒜 5 瓣\n",
      "- 青红椒各 1 个\n",
      "- 料酒 1 汤匙\n",
      "- 生抽 1 汤匙\n",
      "- 盐 1/2 茶匙\n",
      "- 白胡椒粉 1/4 茶匙\n",
      "- 糖 1/2 茶匙\n",
      "- 鸡精 1/4 茶匙\n",
      "- 生粉适量\n",
      "- 葱花适量\n",
      "- 食用油适量\n",
      "\n",
      "做法步骤:\n",
      "\n",
      "1. 鸡肉洗净,切成小丁,加入少许料酒、盐和生粉搅拌均匀腌制10分钟备用。\n",
      "\n",
      "2. 干辣椒剪成2厘米长的段,姜、蒜切末备用。\n",
      "\n",
      "3. 热锅凉油,加入腌制好的鸡肉丁煸炒至变色捞出备用。\n",
      "\n",
      "4. 锅中留底油,加入干辣椒、姜蒜末煸炒出香味,加入青红椒继续煸炒。\n",
      "\n",
      "5. 加入1汤匙生抽、1/2茶匙盐、1/4茶匙白胡椒粉、1/2茶匙糖和1/4茶匙鸡精翻炒均匀。\n",
      "\n",
      "6. 加入炒好的鸡肉丁翻炒均匀,再加入葱花炒匀即可。\n",
      "\n",
      "7. 装盘即可享用。\n",
      "\n",
      "注意事项:\n",
      "\n",
      "1. 鸡肉要切成小丁,这样更容易熟透。\n",
      "\n",
      "2. 干辣椒可以先炒香,再切成小段。\n",
      "\n",
      "3. 姜、蒜末和青红椒要炒出香味,这样才能让调料更好地渗透到鸡肉中。\n",
      "\n",
      "4. 鸡精和白胡椒粉的用量要根据个人口味适量调整。\n"
     ]
    }
   ],
   "source": [
    "# 测试当前模型的能力\n",
    "response, his = model.chat(tokenizer, '宫保鸡丁', history=[])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0e8a59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37236f5a",
   "metadata": {},
   "source": [
    "我们以自己收集的中文菜谱数据为例，介绍如何让大语言模型ChatGLM拥有新的技能。\n",
    "通常来讲调优模型有以下几种方式：\n",
    "1. 重新在新的数据集上训练模型，让模型具有相关的能力；\n",
    "2. 使用预训练（pretrained）的模型为基础，在新的数据集上fine-tuning，使得模型具有新的技能；\n",
    "3. 使用参数有效的调优策略（Parameter-Efficient Fine-Tuning，peft）给预训练模型打补丁，以补丁的形式让模型具备新的技能。\n",
    "\n",
    "通常来说，对于1和2适用于小模型，一般是亿级以下参数量的模型。对于ChatGLM2-6b模型，其参数量为60亿，采用1和2的方式调优模型，必然会导致GPU的显存不够，造成OOM错误。因此，本示例采用3来调优ChatGLM2-6b模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bed2b2b",
   "metadata": {},
   "source": [
    "### 1. 数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a832a6",
   "metadata": {},
   "source": [
    "#### 1.1 处理数据，提取必要的信息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f184db15",
   "metadata": {},
   "source": [
    "数据总共包括136048条菜谱数据，数据类型如下：\n",
    "    ```json\n",
    "    {\n",
    "      \"id\": \"1\",\n",
    "      \"title\": \"红烧鸡翅\",\n",
    "      \"intro\": \"\",\n",
    "      \"image\": \"http://i8.meishichina.com/attachment/recipe/200910/200910120907019.jpg@!p800\",\n",
    "      \"steps\": [\n",
    "        {\n",
    "          \"index\": 1,\n",
    "          \"image\": \"\",\n",
    "          \"content\": \"鸡翅洗净抹干水分，加入腌料拌匀，腌制1小时\"\n",
    "        },\n",
    "        {\n",
    "          \"index\": 2,\n",
    "          \"image\": \"\",\n",
    "          \"content\": \"牛腩切3厘米左右的块；土豆一半切1厘米小块另一半切3厘米左右的块；洋葱切碎，至于是切块还是切条切丝，大家随意啊；胡萝卜切的小一点，会入味，甜甜的。\"\n",
    "        },\n",
    "        {\n",
    "          \"index\": 3,\n",
    "          \"image\": \"\",\n",
    "          \"content\": \"很疑惑\"\n",
    "        }\n",
    "      ],\n",
    "      \"ingredients\": {\n",
    "        \"鸡翅中\": \"8个\",\n",
    "        \"姜（腌料）\": \"2片\",\n",
    "        \"葱（腌料）\": \"2根\",\n",
    "        \"盐（腌料）\": \"4克\",\n",
    "        \"料酒（调料A）\": \"半汤勺\",\n",
    "        \"酱油（调料A）\": \"1汤勺\",\n",
    "        \"胡椒粉（调料A）\": \"少许\",\n",
    "        \"蚝油（调料B）\": \"2汤勺\",\n",
    "        \"糖（调料B）\": \"1茶勺\",\n",
    "        \"麻油（调料B）\": \"少许\"\n",
    "      },\n",
    "      \"tags\": [],\n",
    "      \"notice\": \"特点：色泽酱红，鲜香酥嫩。\\n小提示：挑选鸡翅时，为了受热均匀，最好全部选用鸡翅中段。\",\n",
    "      \"level\": \"普通\",\n",
    "      \"craft\": \"烧\",\n",
    "      \"duration\": \"一小时\",\n",
    "      \"flavor\": \"原味\"\n",
    "    }\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bba421b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def process_mstx(data_file):\n",
    "    with open(data_file, 'r', encoding='utf-8-sig') as fd:\n",
    "        meishi_json = json.load(fd)\n",
    "    \n",
    "    print(f\"总共有{len(meishi_json)}个菜品\")\n",
    "    print(json.dumps(meishi_json[0], indent=2, ensure_ascii=False))\n",
    "    \n",
    "    data = []\n",
    "    for food in meishi_json:\n",
    "        # 食品名称\n",
    "        food_name = food[\"title\"]\n",
    "        # 食材明细\n",
    "        ingredient = \"\"\n",
    "        for k,v in food[\"ingredients\"].items():\n",
    "            ingredient += f\"{k} : {v} \\n\"\n",
    "        # 制作步骤\n",
    "        step = \"\"\n",
    "        for st in food[\"steps\"]:\n",
    "            step += f\"第{st['index']}步：{st['content']}\"\n",
    "            \n",
    "        #制作方法\n",
    "        craft = \"\" if food['craft'] is None else food['craft']\n",
    "        duration = \"\" if food['duration'] is None else food['duration']\n",
    "        method = craft + duration\n",
    "        \n",
    "        # 构建数据\n",
    "        data.append({\n",
    "            \"id\": food['id'],\n",
    "            \"菜品名称\": food_name,\n",
    "            \"食材明细\": ingredient,\n",
    "            \"制作步骤\": step,\n",
    "            \"制作方法\": method,\n",
    "        })\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1f62a4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总共有136048个菜品\n",
      "{\n",
      "  \"id\": \"1\",\n",
      "  \"title\": \"红烧鸡翅\",\n",
      "  \"intro\": \"\",\n",
      "  \"image\": \"http://i8.meishichina.com/attachment/recipe/200910/200910120907019.jpg@!p800\",\n",
      "  \"steps\": [\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"image\": \"\",\n",
      "      \"content\": \"鸡翅洗净抹干水分，加入腌料拌匀，腌制1小时\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"image\": \"\",\n",
      "      \"content\": \"牛腩切3厘米左右的块；土豆一半切1厘米小块另一半切3厘米左右的块；洋葱切碎，至于是切块还是切条切丝，大家随意啊；胡萝卜切的小一点，会入味，甜甜的。\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 3,\n",
      "      \"image\": \"\",\n",
      "      \"content\": \"很疑惑\"\n",
      "    }\n",
      "  ],\n",
      "  \"ingredients\": {\n",
      "    \"鸡翅中\": \"8个\",\n",
      "    \"姜（腌料）\": \"2片\",\n",
      "    \"葱（腌料）\": \"2根\",\n",
      "    \"盐（腌料）\": \"4克\",\n",
      "    \"料酒（调料A）\": \"半汤勺\",\n",
      "    \"酱油（调料A）\": \"1汤勺\",\n",
      "    \"胡椒粉（调料A）\": \"少许\",\n",
      "    \"蚝油（调料B）\": \"2汤勺\",\n",
      "    \"糖（调料B）\": \"1茶勺\",\n",
      "    \"麻油（调料B）\": \"少许\"\n",
      "  },\n",
      "  \"tags\": [],\n",
      "  \"notice\": \"特点：色泽酱红，鲜香酥嫩。\\n小提示：挑选鸡翅时，为了受热均匀，最好全部选用鸡翅中段。\",\n",
      "  \"level\": \"普通\",\n",
      "  \"craft\": \"烧\",\n",
      "  \"duration\": \"一小时\",\n",
      "  \"flavor\": \"原味\"\n",
      "}\n",
      "{'id': '1', '菜品名称': '红烧鸡翅', '食材明细': '鸡翅中 : 8个 \\n姜（腌料） : 2片 \\n葱（腌料） : 2根 \\n盐（腌料） : 4克 \\n料酒（调料A） : 半汤勺 \\n酱油（调料A） : 1汤勺 \\n胡椒粉（调料A） : 少许 \\n蚝油（调料B） : 2汤勺 \\n糖（调料B） : 1茶勺 \\n麻油（调料B） : 少许 \\n', '制作步骤': '第1步：鸡翅洗净抹干水分，加入腌料拌匀，腌制1小时第2步：牛腩切3厘米左右的块；土豆一半切1厘米小块另一半切3厘米左右的块；洋葱切碎，至于是切块还是切条切丝，大家随意啊；胡萝卜切的小一点，会入味，甜甜的。第3步：很疑惑', '制作方法': '烧一小时'}\n"
     ]
    }
   ],
   "source": [
    "data_file = \"./mstx-中文菜谱.json\"\n",
    "meishi_data = process_mstx(data_file)\n",
    "print(meishi_data[0])\n",
    "\n",
    "processed_data_file = 'mstx-中文菜谱-processed.json'\n",
    "with open(processed_data_file, 'w', encoding='utf-8') as fd:\n",
    "        fd.write(json.dumps(meishi_data, indent=4, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a21913",
   "metadata": {},
   "source": [
    "#### 1.2 构建训练数据的prompt\n",
    "\n",
    "在本示例中，我们构建三种类型的prompt，即：\n",
    "1. 给定菜名，生成制作方法+食材+步骤\n",
    "2. 给出制作方法+食材+步骤，生成菜名；\n",
    "3. 判断给定的菜名和制作方法+食材+步骤是否匹配。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "92b32be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import datasets\n",
    "import pandas as pd\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "439bca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_foodname_methods_prompt(data_file, prompt = \"\"):\n",
    "    '''\n",
    "    给菜名，生成制作方法+步骤+食材\n",
    "    '''\n",
    "    with open(data_file, \"r\", encoding='utf8') as f:\n",
    "        caipu_json = json.load(f)\n",
    "    print(f'总共有{len(caipu_json)}个菜品')\n",
    "\n",
    "    data = []\n",
    "    for caiming in caipu_json:\n",
    "        # print(caiming['id'])\n",
    "        # 菜品名称\n",
    "        food_name = caiming[\"菜品名称\"]\n",
    "\n",
    "        # 食材明细\n",
    "        ingredient = caiming[\"食材明细\"]\n",
    "\n",
    "        # 制作步骤\n",
    "        step = caiming[\"制作步骤\"]\n",
    "\n",
    "        # 制作方法\n",
    "        method = caiming[\"制作方法\"]\n",
    "\n",
    "        # 构建prompt\n",
    "        prompt_item = {'prompt' : prompt + food_name, 'response':\n",
    "            '\\n' + '食材明细: \\n' + ingredient + '\\n' + \"制作步骤: \\n\" +  step + '\\n' +\n",
    "            \"制作方法: \\n\" + method + '\\n'}\n",
    "        data.append(prompt_item)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d5a9f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_methods_foodname_prompt(data_file, prompt=\"\"):\n",
    "    '''\n",
    "    给食材+制作方法+步骤，生成菜名\n",
    "    '''\n",
    "    with open(data_file, \"r\", encoding='utf8') as f:\n",
    "        caipu_json = json.load(f)\n",
    "    print(f'总共有{len(caipu_json)}个菜品')\n",
    "\n",
    "    data = []\n",
    "    for caiming in caipu_json:\n",
    "        # print(caiming['id'])\n",
    "        # 菜品名称\n",
    "        food_name = caiming[\"菜品名称\"]\n",
    "\n",
    "        # 食材明细\n",
    "        ingredient = caiming[\"食材明细\"]\n",
    "\n",
    "        # 制作步骤\n",
    "        step = caiming[\"制作步骤\"]\n",
    "\n",
    "        # 制作方法\n",
    "        method = caiming[\"制作方法\"]\n",
    "\n",
    "        # 构建prompt\n",
    "        prompt_item = {'prompt': prompt + '\\n' + '食材明细: \\n' + ingredient + '\\n' + \"制作步骤: \\n\" + step + '\\n' +\n",
    "            \"制作方法: \\n\" + method + '\\n', 'response': \"以上步骤是菜品 (\" + food_name + \") 的制作方法 \\n\"}\n",
    "        data.append(prompt_item)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "973e80b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_foodname_match_methods_prompt(\n",
    "        data_file,\n",
    "        neg_sample_num=2,\n",
    "        prompt=\"文本分类任务：判断菜品与制作方式的匹配醒进行判断，分成匹配和不匹配\"):\n",
    "    '''\n",
    "    给出 菜名 + 食材 + 制作方法 + 步骤， 给出判断是否匹配\n",
    "    '''\n",
    "    with open(data_file, \"r\", encoding='utf8') as f:\n",
    "        caipu_json = json.load(f)\n",
    "    total_food = len(caipu_json)\n",
    "    print(f'总共有{total_food}个菜品')\n",
    "\n",
    "    data = []\n",
    "    for caiming in caipu_json:\n",
    "        # print()\n",
    "        id = caiming['id']\n",
    "        # 菜品名称\n",
    "        food_name = caiming[\"菜品名称\"]\n",
    "\n",
    "        # 食材明细\n",
    "        ingredient = caiming[\"食材明细\"]\n",
    "\n",
    "        # 制作步骤\n",
    "        step = caiming[\"制作步骤\"]\n",
    "\n",
    "        # 制作方法\n",
    "        method = caiming[\"制作方法\"]\n",
    "\n",
    "        prompt1 = prompt + '\\n' + f\"烹制{food_name}的方式如下:\\n\" + '食材明细: \\n' + ingredient + '\\n' + \"制作步骤: \\n\" + step + \\\n",
    "                 '\\n' + \"制作方法: \\n\" + method + '\\n'\n",
    "        prompt2 = prompt + '\\n' + f\"烹制{food_name}的方式如下:\\n\" + '\\n' + \"制作步骤: \\n\" + step + '食材明细: \\n' + ingredient + \\\n",
    "                  '\\n' + \"制作方法: \\n\" + method + '\\n'\n",
    "        prompt3 = prompt + '\\n' + f\"烹制{food_name}的方式如下:\\n\" + '\\n' + \"制作步骤: \\n\" + step + \\\n",
    "                  '\\n' + \"制作方法: \\n\" + method + '食材明细: \\n' + ingredient + '\\n'\n",
    "        prompt4 = prompt + '\\n' + f\"烹制{food_name}的方式如下:\\n\" + '食材明细: \\n' + ingredient + '\\n' + \\\n",
    "                  '\\n' + \"制作方法: \\n\" + method + \"制作步骤: \\n\" + step + '\\n'\n",
    "        data.append({\"prompt\": prompt1, \"response\": \"上述菜名与烹饪方式是匹配的\"})\n",
    "        data.append({\"prompt\": prompt2, \"response\": \"上述菜名与烹饪方式是匹配的\"})\n",
    "        data.append({\"prompt\": prompt3, \"response\": \"上述菜名与烹饪方式是匹配的\"})\n",
    "        data.append({\"prompt\": prompt4, \"response\": \"上述菜名与烹饪方式是匹配的\"})\n",
    "\n",
    "        sample_num = 0\n",
    "        while True:\n",
    "            sample_id = random.randint(0, total_food-1)\n",
    "            if sample_id == id:\n",
    "                continue\n",
    "            sample_num += 1\n",
    "            if sample_num > neg_sample_num:\n",
    "                break\n",
    "            neg_caiming = caipu_json[sample_id]\n",
    "            neg_food_name = neg_caiming[\"菜品名称\"]\n",
    "            neg_ingredient = neg_caiming[\"食材明细\"]\n",
    "            neg_step = neg_caiming[\"制作步骤\"]\n",
    "            neg_method = neg_caiming[\"制作方法\"]\n",
    "\n",
    "            prompt1 = prompt + '\\n' + f\"烹制{food_name}的方式如下:\\n\" + '食材明细: \\n' + neg_ingredient + '\\n' +\\\n",
    "                      \"制作步骤: \\n\" + neg_step + '\\n' + \"制作方法: \\n\" + neg_method + '\\n'\n",
    "            prompt2 = prompt + '\\n' + f\"烹制{neg_food_name}的方式如下:\\n\" + '食材明细: \\n' + ingredient + '\\n' + \"制作步骤: \\n\" + step + \\\n",
    "                      '\\n' + \"制作方法: \\n\" + method + '\\n'\n",
    "            data.append({\"prompt\": prompt1, \"response\": \"上述菜名与烹饪方式是不匹配的\"})\n",
    "            data.append({\"prompt\": prompt2, \"response\": \"上述菜名与烹饪方式是不匹配的\"})\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c8cd9cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_comcate(data_file):\n",
    "    '''\n",
    "    划分训练集和测试集，按照各自数据的8：2划分\n",
    "    '''\n",
    "    mathch_data = build_foodname_match_methods_prompt(data_file)\n",
    "    print(f'一共产生数据: {len(mathch_data)} 条')\n",
    "    mathch_data = pd.DataFrame(mathch_data)\n",
    "    mathch_data_ds = datasets.Dataset.from_pandas(mathch_data).train_test_split(test_size=0.2, shuffle=True, seed=42)\n",
    "\n",
    "    food_data = build_foodname_methods_prompt(data_file)\n",
    "    print(f'一共产生数据: {len(food_data)} 条')\n",
    "    food_data = pd.DataFrame(food_data)\n",
    "    food_data_ds = datasets.Dataset.from_pandas(food_data).train_test_split(test_size=0.2, shuffle=True, seed=42)\n",
    "\n",
    "    method_data = build_methods_foodname_prompt(data_file)\n",
    "    print(f'一共产生数据: {len(method_data)} 条')\n",
    "    method_data = pd.DataFrame(method_data)\n",
    "    method_data_ds = datasets.Dataset.from_pandas(method_data).train_test_split(test_size=0.2, shuffle=True, seed=42)\n",
    "\n",
    "    train_data = pd.concat([mathch_data_ds['train'].to_pandas(), food_data_ds['train'].to_pandas(),\n",
    "                               method_data_ds['train'].to_pandas()])\n",
    "    test_data = pd.concat([mathch_data_ds['test'].to_pandas(), food_data_ds['test'].to_pandas(),\n",
    "                               method_data_ds['test'].to_pandas()])\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d8d78d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总共有136048个菜品\n",
      "一共产生数据: 1088384 条\n",
      "总共有136048个菜品\n",
      "一共产生数据: 136048 条\n",
      "总共有136048个菜品\n",
      "一共产生数据: 136048 条\n",
      "(1088383, 2)\n",
      "(272097, 2)\n",
      "                                              prompt       response\n",
      "0  文本分类任务：判断菜品与制作方式的匹配醒进行判断，分成匹配和不匹配\\n烹制第一次做——简简单...  上述菜名与烹饪方式是匹配的\n",
      "1  文本分类任务：判断菜品与制作方式的匹配醒进行判断，分成匹配和不匹配\\n烹制彩色饺子的方式如下...  上述菜名与烹饪方式是匹配的\n",
      "2  文本分类任务：判断菜品与制作方式的匹配醒进行判断，分成匹配和不匹配\\n烹制百姓家的普通饭--...  上述菜名与烹饪方式是匹配的\n",
      "3  文本分类任务：判断菜品与制作方式的匹配醒进行判断，分成匹配和不匹配\\n烹制豆角木耳粉丝鸡蛋馅...  上述菜名与烹饪方式是匹配的\n",
      "4  文本分类任务：判断菜品与制作方式的匹配醒进行判断，分成匹配和不匹配\\n烹制黄金Q虾棒的方式如...  上述菜名与烹饪方式是匹配的\n",
      "5  文本分类任务：判断菜品与制作方式的匹配醒进行判断，分成匹配和不匹配\\n烹制芝麻酱拌生菜的方式...  上述菜名与烹饪方式是匹配的\n",
      "6  文本分类任务：判断菜品与制作方式的匹配醒进行判断，分成匹配和不匹配\\n烹制三鲜汤的方式如下:...  上述菜名与烹饪方式是匹配的\n",
      "7  文本分类任务：判断菜品与制作方式的匹配醒进行判断，分成匹配和不匹配\\n烹制薄皮馅饼的方式如下...  上述菜名与烹饪方式是匹配的\n",
      "8  文本分类任务：判断菜品与制作方式的匹配醒进行判断，分成匹配和不匹配\\n烹制简单的辅食的方式如...  上述菜名与烹饪方式是匹配的\n",
      "9  文本分类任务：判断菜品与制作方式的匹配醒进行判断，分成匹配和不匹配\\n烹制红薯包子的方式如下...  上述菜名与烹饪方式是匹配的\n"
     ]
    }
   ],
   "source": [
    "# 将数据按照相应的prompt构建，并划分训练数据和测试数据\n",
    "\n",
    "processed_data_file = 'mstx-中文菜谱-processed.json'\n",
    "train_data, test_data = split_and_comcate(processed_data_file)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(train_data.head(10))\n",
    "train_data.to_parquet('train_data.parquet')\n",
    "test_data.to_parquet('test_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "49f99c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = datasets.Dataset.from_pandas(train_data)\n",
    "ds_test = datasets.Dataset.from_pandas(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a43f28",
   "metadata": {},
   "source": [
    "### 2. token编码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f37732",
   "metadata": {},
   "source": [
    "为了将文本数据喂入模型，需要将词转换为token。也就是把prompt转化成prompt_ids，把response转化成response_ids.\n",
    "\n",
    "同时，我们还需要将prompt_ids和response_ids拼接到一起作为模型的input_ids。\n",
    "\n",
    "这是为什么呢？\n",
    "\n",
    "因为ChatGLM2基座模型是一个TransformerDecoder结构，是一个被预选练过的纯粹的语言模型(LLM，Large Lauguage Model)。\n",
    "\n",
    "一个纯粹的语言模型，本质上只能做一件事情，那就是计算任意一段话像'人话'的概率。\n",
    "\n",
    "我们将prompt和response拼接到一起作为input_ids， ChatGLM2 就可以判断这段对话像'人类对话'的概率。\n",
    "\n",
    "在训练的时候我们使用梯度下降的方法来让ChatGLM2的判断更加准确。\n",
    "\n",
    "训练完成之后，在预测的时候，我们就可以利用贪心搜索或者束搜索的方法按照最像\"人类对话\"的方式进行更合理的文本生成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d5a6b462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import transformers\n",
    "\n",
    "# model_name = \"../chatglm2-6b\" #chatglm2-6b模型保存路径\n",
    "max_seq_length = 1024\n",
    "skip_over_length = True\n",
    "\n",
    "#tokenizer = transformers.AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "config = transformers.AutoConfig.from_pretrained(model_name, trust_remote_code=True, device_map='auto')\n",
    "\n",
    "def preprocess(example):\n",
    "    context = example[\"prompt\"]\n",
    "    target = example[\"response\"]\n",
    "    \n",
    "    context_ids = tokenizer.encode(\n",
    "            context, \n",
    "            max_length=max_seq_length,\n",
    "            truncation=True)\n",
    "    \n",
    "    target_ids = tokenizer.encode(\n",
    "        target,\n",
    "        max_length=max_seq_length,\n",
    "        truncation=True,\n",
    "        add_special_tokens=False)\n",
    "    \n",
    "    input_ids = context_ids + target_ids + [config.eos_token_id]\n",
    "    \n",
    "    # -100标志位后面会在计算loss时会被忽略不贡献损失，我们集中优化target部分生成的loss\n",
    "    labels = [-100]*len(context_ids)+ target_ids + [config.eos_token_id]\n",
    "    \n",
    "    return {\"input_ids\": input_ids,\n",
    "            \"labels\": labels,\n",
    "            \"context_len\": len(context_ids),\n",
    "            'target_len':len(target_ids)+1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "90c87bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1088383 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1088383 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_train_token = ds_train.map(preprocess).select_columns(['input_ids','labels', 'context_len','target_len'])\n",
    "#len_ids = [len(example[\"input_ids\"]) for example in ds_train_token]\n",
    "#longest = max(len_ids)\n",
    "#print(longest)\n",
    "if skip_over_length:\n",
    "    ds_train_token = ds_train_token.filter(\n",
    "        lambda example: example[\"context_len\"]<max_seq_length and example[\"target_len\"]<max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e1ae98e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len_ids = [len(example[\"input_ids\"]) for example in ds_train_token]\n",
    "#longest = max(len_ids)\n",
    "#print(longest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "87d52a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/272097 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/272097 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_test_token = ds_test.map(preprocess).select_columns(['input_ids', 'labels','context_len','target_len'])\n",
    "#len_ids = [len(example[\"input_ids\"]) for example in ds_test_token]\n",
    "#longest = max(len_ids)\n",
    "#print(longest)\n",
    "if skip_over_length:\n",
    "    ds_val_token = ds_test_token.filter(\n",
    "        lambda example: example[\"context_len\"]<max_seq_length and example[\"target_len\"]<max_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287532fb",
   "metadata": {},
   "source": [
    "#### 2.1 构建训练数据管道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "90ccb6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collator(examples: list):\n",
    "    len_ids = [len(example[\"input_ids\"]) for example in examples]\n",
    "    longest = max(len_ids) #之后按照batch中最长的input_ids进行padding\n",
    "    \n",
    "    input_ids = []\n",
    "    labels_list = []\n",
    "    \n",
    "    for length, example in sorted(zip(len_ids, examples), key=lambda x: -x[0]):\n",
    "        ids = example[\"input_ids\"]\n",
    "        labs = example[\"labels\"]\n",
    "        \n",
    "        ids = ids + [tokenizer.pad_token_id] * (longest - length)\n",
    "        labs = labs + [-100] * (longest - length)\n",
    "        \n",
    "        input_ids.append(torch.LongTensor(ids))\n",
    "        labels_list.append(torch.LongTensor(labs))\n",
    "          \n",
    "    input_ids = torch.stack(input_ids)\n",
    "    labels = torch.stack(labels_list)\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"labels\": labels,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2cd45ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "dl_train = torch.utils.data.DataLoader(ds_train_token,num_workers=2,batch_size=8,\n",
    "                                       pin_memory=True,shuffle=True, collate_fn = data_collator)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test_token,num_workers=2,batch_size=8,\n",
    "                                    pin_memory=True,shuffle=True, collate_fn = data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b7f32ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[64790, 64792, 30910,  ..., 36336, 54530,     2],\n",
       "         [64790, 64792, 30910,  ...,     0,     0,     0],\n",
       "         [64790, 64792, 30910,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [64790, 64792, 30910,  ...,     0,     0,     0],\n",
       "         [64790, 64792, 30910,  ...,     0,     0,     0],\n",
       "         [64790, 64792, 30910,  ...,     0,     0,     0]]),\n",
       " 'labels': tensor([[ -100,  -100,  -100,  ..., 36336, 54530,     2],\n",
       "         [ -100,  -100,  -100,  ...,  -100,  -100,  -100],\n",
       "         [ -100,  -100,  -100,  ...,  -100,  -100,  -100],\n",
       "         ...,\n",
       "         [ -100,  -100,  -100,  ...,  -100,  -100,  -100],\n",
       "         [ -100,  -100,  -100,  ...,  -100,  -100,  -100],\n",
       "         [ -100,  -100,  -100,  ...,  -100,  -100,  -100]])}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in dl_train:\n",
    "    break \n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d674c62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dl_train.size = 300\n",
    "# dl_test.size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dc05df",
   "metadata": {},
   "source": [
    "### 3. 构建模型\n",
    "\n",
    "本示例使用QLoRA来调优ChatGLM2-6B模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6dad32e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3ee071aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, TrainingArguments, AutoConfig\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# model = AutoModel.from_pretrained(\"../chatglm2-6b\",\n",
    "#                                  load_in_8bit=False,  #是否导入int8量化模型\n",
    "#                                  trust_remote_code=True)\n",
    "\n",
    "model.supports_gradient_checkpointing = True  #节约cuda\n",
    "model.gradient_checkpointing_enable()\n",
    "model.enable_input_require_grads()\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6b5d5c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预处理量化模型，以适配LoRA调优\n",
    "from peft import prepare_model_for_kbit_training\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "61a0ba8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# 找出所有的全连接，为全连接层添加LoRA适配器\n",
    "#!pip install scipy\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "def find_all_linear_modules(model):\n",
    "    cls = bnb.nn.Linear4bit\n",
    "    lora_module_names = set()\n",
    "    \n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(name[0] if len(names) == 1 else names[-1])\n",
    "            \n",
    "    if \"lm_head\" in lora_module_names:\n",
    "        lora_module_names.remove(\"lm_head\")\n",
    "    return list(lora_module_names)\n",
    "\n",
    "lora_modules = find_all_linear_modules(model)\n",
    "print(lora_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e7ad5a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,949,696 || all params: 6,245,533,696 || trainable%: 0.031217444255383614\n"
     ]
    }
   ],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, \n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32, \n",
    "    lora_dropout=0.1,\n",
    "    #target_modules=lora_modules\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.is_parallelizable = True\n",
    "model.model_parallel = True\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4a88e0",
   "metadata": {},
   "source": [
    "### 4. 训练模型\n",
    "\n",
    "此处我们使用torchkeras工具包来构建训练流程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "44958019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchkeras import KerasModel \n",
    "from accelerate import Accelerator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "569091f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepRunner:\n",
    "    def __init__(self, net, loss_fn, accelerator=None, stage = \"train\", metrics_dict = None, \n",
    "                 optimizer = None, lr_scheduler = None\n",
    "                 ):\n",
    "        self.net,self.loss_fn,self.metrics_dict,self.stage = net,loss_fn,metrics_dict,stage\n",
    "        self.optimizer,self.lr_scheduler = optimizer,lr_scheduler\n",
    "        self.accelerator = accelerator if accelerator is not None else Accelerator() \n",
    "        if self.stage=='train':\n",
    "            self.net.train() \n",
    "        else:\n",
    "            self.net.eval()\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        \n",
    "        #loss\n",
    "        with self.accelerator.autocast():\n",
    "            loss = self.net(input_ids=batch[\"input_ids\"],labels=batch[\"labels\"]).loss\n",
    "\n",
    "        #backward()\n",
    "        if self.optimizer is not None and self.stage==\"train\":\n",
    "            self.accelerator.backward(loss)\n",
    "            if self.accelerator.sync_gradients:\n",
    "                self.accelerator.clip_grad_norm_(self.net.parameters(), 1.0)\n",
    "            self.optimizer.step()\n",
    "            if self.lr_scheduler is not None:\n",
    "                self.lr_scheduler.step()\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "        all_loss = self.accelerator.gather(loss).sum()\n",
    "        \n",
    "        #losses (or plain metrics that can be averaged)\n",
    "        step_losses = {self.stage+\"_loss\":all_loss.item()}\n",
    "        \n",
    "        #metrics (stateful metrics)\n",
    "        step_metrics = {}\n",
    "        \n",
    "        if self.stage==\"train\":\n",
    "            if self.optimizer is not None:\n",
    "                step_metrics['lr'] = self.optimizer.state_dict()['param_groups'][0]['lr']\n",
    "            else:\n",
    "                step_metrics['lr'] = 0.0\n",
    "        return step_losses,step_metrics\n",
    "    \n",
    "KerasModel.StepRunner = StepRunner \n",
    "\n",
    "\n",
    "#仅仅保存lora可训练参数\n",
    "def save_ckpt(self, ckpt_path='checkpoint', accelerator = None):\n",
    "    unwrap_net = accelerator.unwrap_model(self.net)\n",
    "    unwrap_net.save_pretrained(ckpt_path)\n",
    "    \n",
    "def load_ckpt(self, ckpt_path='checkpoint'):\n",
    "    self.net = self.net.from_pretrained(self.net,ckpt_path)\n",
    "    self.from_scratch = False\n",
    "    \n",
    "KerasModel.save_ckpt = save_ckpt \n",
    "KerasModel.load_ckpt = load_ckpt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "15d5a9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = KerasModel(model,loss_fn = None,optimizer=torch.optim.AdamW(model.parameters(),lr=2e-6))\n",
    "ckpt_path = 'meishi_chatglm2_qlora'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7fdee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m<<<<<< ⚡️ cuda is used >>>>>>\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* background: */\n",
       "    progress::-webkit-progress-bar {background-color: #CDCDCD; width: 100%;}\n",
       "    progress {background-color: #CDCDCD;}\n",
       "\n",
       "    /* value: */\n",
       "    progress::-webkit-progress-value {background-color: #00BFFF  !important;}\n",
       "    progress::-moz-progress-bar {background-color: #00BFFF  !important;}\n",
       "    progress {color: #00BFFF ;}\n",
       "\n",
       "    /* optional */\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #000000;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0% [0/5]\n",
       "      <br>\n",
       "                          0.36% [487/135929] [train_loss=4.57890,lr=0.00000]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keras_model.fit(train_data = dl_train,\n",
    "                val_data = dl_test,\n",
    "                epochs=5,\n",
    "                patience=3, #for early stop\n",
    "                monitor='val_loss',\n",
    "                mode='min',\n",
    "                ckpt_path = ckpt_path,\n",
    "                gradient_accumulation_steps=4\n",
    "                #mixed_precision='fp16'\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966201b3",
   "metadata": {},
   "source": [
    "### 5. 验证模型\n",
    "\n",
    "根据已训练好的模型，来验证模型的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37d94587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "214a8284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm2-6b:\n",
      "- tokenization_chatglm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm2-6b:\n",
      "- configuration_chatglm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm2-6b:\n",
      "- quantization.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm2-6b:\n",
      "- modeling_chatglm.py\n",
      "- quantization.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c53149bb2ac41de8a57d8e2e07828b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b950a2781f9644279f2e599089117428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import  AutoModel,AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "\n",
    "model_name = \"THUDM/chatglm2-6b\" #\"../chatglm2-6b\" #或者远程 “THUDM/chatglm2-6b”\n",
    "ckpt_path = 'meishi_chatglm2_qlora'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True, #QLoRA 设计的 Double Quantization\n",
    "    bnb_4bit_quant_type='nf4', # QLoRA 设计的 Normal Float 4 量化数据类型\n",
    "    llm_int8_threshold=6.0,\n",
    "    llm_int8_has_fp16_weight=False,\n",
    ")\n",
    "\n",
    "model = AutoModel.from_pretrained(model_name,\n",
    "                                  load_in_8bit=False,\n",
    "                                  trust_remote_code=True,\n",
    "                                  device_map='auto')\n",
    "\n",
    "model = PeftModel.from_pretrained(model, ckpt_path)\n",
    "model = model.merge_and_unload() # 合并QLoRA的权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c9a197c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "食材明细: \n",
      "香蕉 : 1根 \n",
      "西米 : 适量 \n",
      "牛奶 : 适量 \n",
      "\n",
      "制作步骤: \n",
      "第1步：香蕉去皮切成小丁，牛奶中加少许盐，香蕉丁放入牛奶中拌匀。第2步：把香蕉牛奶倒入小碗里，放入冰箱冷冻至凝固。第3步：小碗里放入西米。第4步：加入少许水，盖盖子。第5步：放入冰箱冷冻至凝固。第6步：凝固后取出香蕉牛奶西米捞，加入少许糖。第7步：再加入香蕉丁。第8步：最后加入牛奶。第9步：拌匀即可。\n",
      "制作方法: \n",
      "其他十分钟\n"
     ]
    }
   ],
   "source": [
    "# 测试新模型的能力\n",
    "response, his = model.chat(tokenizer, '蕉牛奶西米捞', history=[])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6877e54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "食材明细: \n",
      "黄瓜 : 1根 \n",
      "辣椒 : 2个 \n",
      "蒜 : 1个 \n",
      "盐 : 适量 \n",
      "油 : 适量 \n",
      "醋 : 适量 \n",
      "\n",
      "制作步骤: \n",
      "\n",
      "制作方法: \n",
      "拌十分钟\n"
     ]
    }
   ],
   "source": [
    "response, his = model.chat(tokenizer, '辣拌脆黄瓜', history=[])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43d14ce9-8fb9-4af8-b559-f4e08fa7ff63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以上步骤是菜品【沙茶牛肉】的制作方法\n"
     ]
    }
   ],
   "source": [
    "integrate = \"牛肉片 : 300克 \\n青椒片 : 75克 \\n洋葱片 : 50克 \\n沙茶酱 : 75克 \\n白糖 : 20克 \\n白酱油 : 20克 \\n淀粉 : 30克 \\n蒜末 : 10克 \\n花生酱 : 35克 \\n味精 : 3克 \\n熟猪油 : 适量 \\n\"\n",
    "step = \"第1步：牛肉片用白酱油抓匀，再加淀粉拌匀。第2步：将牛肉片加入沙茶酱、花生酱、白糖、蒜末、味精、再放入青椒片、洋葱片淋上熟猪油拌匀，用高档火打6分钟即可。\"\n",
    "method = \"炒廿分钟\"\n",
    "prompt = \"\" + '\\n' + '食材明细: \\n' + integrate + '\\n' + \"制作步骤: \\n\" + step + '\\n' + \"制作方法: \\n\" + method + '\\n'\n",
    "response, his = model.chat(tokenizer, prompt, history=[])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b991003d-5e91-4fd5-89d7-66f461e95627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
